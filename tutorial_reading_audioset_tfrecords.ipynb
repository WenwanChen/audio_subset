{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites:\n",
    "Please download the following files before you begin this tutorial:\n",
    "- [balanced_train_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv)\n",
    "- [unbalanced_train_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/unbalanced_train_segments.csv)\n",
    "- [eval_segments.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/eval_segments.csv)\n",
    "- [128-dimension audio features](https://research.google.com/audioset/download.html) i.e., embeddings - About 2GB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`examples` must contain YouTube IDs of all examples for one class. Consider the class `Clapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63,/m/0l15bq,\"Clapping\"\r\n"
     ]
    }
   ],
   "source": [
    "!grep Clapping class_labels_indices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_index = !grep Clapping class_labels_indices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/m/0l15bq\n"
     ]
    }
   ],
   "source": [
    "print class_label_index[0].split(\",\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0FMdORf5iGs, 30.000, 40.000, \"/m/04rlf,/m/081rb,/m/09x0r,/m/0l15bq\"\r\n",
      "1IxBagCJeZc, 150.000, 160.000, \"/m/01j3sz,/m/09x0r,/m/0l15bq\"\r\n",
      "1_DouJRW3PM, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "2y9ikTsTsl0, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "3PliaLqMSqg, 30.000, 40.000, \"/m/028ght,/m/09x0r,/m/0l15bq\"\r\n",
      "3ixOXsKUufM, 30.000, 40.000, \"/m/0l15bq\"\r\n",
      "4mOTOTJLv5U, 0.000, 10.000, \"/m/09x0r,/m/0l15bq,/m/0ytgt\"\r\n",
      "7Ep2a7_sbmc, 260.000, 270.000, \"/m/09x0r,/m/0l15bq\"\r\n",
      "7SpYywlGPyM, 30.000, 40.000, \"/m/09x0r,/m/0k65p,/m/0l15bq,/m/0ytgt\"\r\n",
      "AiGF0850kT8, 6.000, 16.000, \"/m/04rlf,/m/0l15bq\"\r\n"
     ]
    }
   ],
   "source": [
    "!grep /m/0l15bq balanced_train_segments.csv |head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0FMdORf5iGs', '1IxBagCJeZc']\n"
     ]
    }
   ],
   "source": [
    "examples = !grep /m/0l15bq balanced_train_segments.csv | head -2 | cut -c -11\n",
    "print examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_prefixes = set([i[:2] for i in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_filenames = [\"bal_train/\" + i + \".tfrecord\" for i in tfrecord_prefixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings_dict = {}\n",
    "audio_labels_dict = {}\n",
    "#all_tfrecord_filenames = glob.glob(\"bal_train/\" + example[:2] + \".tfrecord\")\n",
    "\n",
    "# Load embeddings\n",
    "sess = tf.Session() \n",
    "for tfrecord in tfrecord_filenames: \n",
    "  for example in tf.python_io.tf_record_iterator(tfrecord):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    vid_id = tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "    if vid_id in examples:\n",
    "      example_label = list(np.asarray(tf_example.features.feature['labels'].int64_list.value))\n",
    "      tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "      n_frames = len(tf_seq_example.feature_lists.feature_list['audio_embedding'].feature)\n",
    "    \n",
    "      audio_frame = []\n",
    "      for i in range(n_frames):\n",
    "        audio_frame.append(tf.cast(tf.decode_raw(\n",
    "             tf_seq_example.feature_lists.feature_list['audio_embedding'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "            ,tf.float32).eval(session=sess))\n",
    "      audio_embeddings_dict[vid_id] = audio_frame\n",
    "      audio_labels_dict[vid_id] = example_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'0FMdORf5iGs': [0, 63, 137, 387], u'1IxBagCJeZc': [0, 16, 63]}\n"
     ]
    }
   ],
   "source": [
    "print audio_labels_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
